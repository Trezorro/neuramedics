## Checking model evaluation
import os
from keras.models import load_model
import pandas as pd
import numpy as np
import os

import matplotlib.pyplot as plt
import seaborn as sns

import keras
import pandas as pd
from keras import backend as K
from keras import layers, models
from keras.utils import np_utils

import scikitplot as skplt
import matplotlib.pyplot as plt

os.getcwd()
os.chdir("/Users/blazejmanczak/Desktop/School/Year2/Q2/DataChallange1")

data_train = np.load("trainDataSmall.npz")
data_test = np.load("testDataSmall.npz")
data_train.files
data_test.files

X_train = data_train["X_train"].astype(np.float32)
Y_train = data_train["Y_train"].astype(np.float32)
X_test = data_test["X_test"].astype(np.float32)
Y_test = data_test["Y_test"].astype(np.float32)

model = load_model('/Users/blazejmanczak/Desktop/School/Year2/Q2/DataChallange1/retinopathy.hdf5')

model.evaluate(X_train, Y_train)

predictions = model.predict(X_test)

def get_binary_probabilities(preds):
    probabs = []
    [probabs.append([i[0], i[1]+i[2]+i[3]+i[4]]) for i in preds]
    return np.array(probabs)

binary_probabs = get_binary_probabilities(predictions)


def get_binary_predictions(preds, threshold):
    binary_preds = []
    [binary_preds.append([1,0]) if i[0]> threshold else binary_preds.append([0,1]) for i in preds]
    return binary_preds

true_binary_Y = get_binary_predcitions(Y_test,0.5)
pred_binary_Y = get_binary_predictions(predictions,0.5)


def get_accuracy(preds, labels):
    counter = 0
    for i in range(len(preds)):
        if preds[i]==labels[i]:
            counter +=1
    return counter/len(preds)

get_accuracy(pred_binary_Y, true_binary_Y)

def get_sensitivity(preds,labels):
    tp = 0
    positivies = 0
    for i in range(len(preds)):
        if labels[i] == [0,1]:
            positivies += 1
            if preds[i]==labels[i]:
                tp +=1
    return tp/positivies

get_sensitivity(pred_binary_Y, true_binary_Y)

def get_specificity(preds, labels):
    tn = 0
    negatives = 0
    for i in range(len(preds)):
        if labels[i] == [1,0]:
            negatives += 1
            if preds[i]==labels[i]:
                tn +=1
    return tn/negatives

get_specificity(pred_binary_Y, true_binary_Y)



def plot_roc(predictions, labels):
    probabs = get_binary_probabilities(predictions)
    lables_no_hot = np.array([0 if i[0]==1 else 1 for i in labels])
    skplt.metrics.plot_roc(lables_no_hot, probabs)
    plt.show()


plot_roc(predictions, true_binary_Y)


y_true = # ground truth labels
y_probas = # predicted probabilities generated by sklearn classifier
true_binary_Y
skplt.metrics.plot_roc_curve(true_binary_Y, binary_probabs)
plt.show()




from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB

X, y = load_digits(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
nb = GaussianNB()
nb.fit(X_train, y_train)
predicted_probas = nb.predict_proba(X_test)


# The magic happens here
import matplotlib.pyplot as plt
import scikitplot as skplt
skplt.metrics.plot_roc(y_test, predicted_probas)
plt.show()
